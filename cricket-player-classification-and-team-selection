{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8890895,"sourceType":"datasetVersion","datasetId":5312813},{"sourceId":9085420,"sourceType":"datasetVersion","datasetId":5481861}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/harshamallubhotla/cricket-player-classification-and-team-selection?scriptVersionId=190895109\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.243906Z","iopub.execute_input":"2024-08-02T12:18:37.244424Z","iopub.status.idle":"2024-08-02T12:18:37.25048Z","shell.execute_reply.started":"2024-08-02T12:18:37.244392Z","shell.execute_reply":"2024-08-02T12:18:37.249133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Read Data**","metadata":{}},{"cell_type":"code","source":"bat = pd.read_csv(r'/kaggle/input/cleaned-cricket-data/bat_stats_clean.csv')\nbowl= pd.read_csv(r'/kaggle/input/cleaned-cricket-data/bowl_stats_clean.csv')\nfield = pd.read_csv(r'/kaggle/input/cleaned-cricket-data/field_stats_clean.csv')\nwik = pd.read_csv(r'/kaggle/input/cleaned-cricket-data/wik_stats_clean.csv')\n\n#bat.head()\n#bowl.head()\n#field.head()\n#wik.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.257895Z","iopub.execute_input":"2024-08-02T12:18:37.258277Z","iopub.status.idle":"2024-08-02T12:18:37.302198Z","shell.execute_reply.started":"2024-08-02T12:18:37.25825Z","shell.execute_reply":"2024-08-02T12:18:37.301016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalize Data**","metadata":{}},{"cell_type":"code","source":"# List of columns to normalize (excluding the 'Player' column)\ncolumns_to_normalize = bat.columns.to_list()[1:]\n\n# Create a new DataFrame 'norm_bat' with the same columns as 'bat'\nnorm_bat = pd.DataFrame(columns=bat.columns)\n\n# Copy the 'Player' column to the new DataFrame\nnorm_bat['Player'] = bat['Player']\n\n# Normalize columns by dividing each value by the column's maximum value\nfor column in columns_to_normalize:\n    max_value = bat[column].max()\n    if column in ['Ducks']:\n        norm_bat[column] = 1 - (bat[column] / max_value)  # Invert normalization for these columns\n    else:\n        norm_bat[column] = bat[column] / max_value  # Normalization for other columns\n\n# Drop the 'Centuries' column from the normalized DataFrame\nnorm_bat.drop('Centuries', axis=1, inplace=True)\n\n# Show the first few rows of the normalized DataFrame\nnorm_bat.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.30406Z","iopub.execute_input":"2024-08-02T12:18:37.304405Z","iopub.status.idle":"2024-08-02T12:18:37.352905Z","shell.execute_reply.started":"2024-08-02T12:18:37.304378Z","shell.execute_reply":"2024-08-02T12:18:37.351668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns to normalize\ncolumns_to_normalize = bowl.columns.to_list()[1:]\nnorm_bowl = pd.DataFrame(columns=bowl.columns)\n# List of columns to normalize (excluding the 'Player' column)\ncolumns_to_normalize = bowl.columns.to_list()[1:]\n\n# Create a new DataFrame 'norm_bowl' with the same columns as 'bowl'\nnorm_bowl = pd.DataFrame(columns=bowl.columns)\n\n# Copy the 'Player' column to the new DataFrame\nnorm_bowl['Player'] = bowl['Player']\n\n# Normalize columns by dividing each value by the column's maximum value\n# For specific columns ('Ave', 'Econ', 'Runs'), invert the normalization\nfor column in columns_to_normalize:\n    max_value = bowl[column].max()\n    if column in ['Ave', 'Econ', 'Runs']:\n        norm_bowl[column] = 1 - (bowl[column] / max_value)  # Invert normalization for these columns\n    else:\n        norm_bowl[column] = bowl[column] / max_value  # Normalization for other columns\n\n# Drop the 'Balls' column from the normalized DataFrame\nnorm_bowl.drop('Balls', axis=1, inplace=True)\n\n# Show the first few rows of the normalized DataFrame\nnorm_bowl.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.354373Z","iopub.execute_input":"2024-08-02T12:18:37.354721Z","iopub.status.idle":"2024-08-02T12:18:37.383654Z","shell.execute_reply.started":"2024-08-02T12:18:37.354692Z","shell.execute_reply":"2024-08-02T12:18:37.382214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of columns to normalize (excluding the 'Player' column)\ncolumns_to_normalize = field.columns.to_list()[1:]\n\n# Create a new DataFrame 'norm_field' with the same columns as 'field'\nnorm_field = pd.DataFrame(columns=field.columns)\n\n# Copy the 'Player' column to the new DataFrame\nnorm_field['Player'] = field['Player']\n\n# Normalize columns by dividing each value by the column's maximum value\nfor column in columns_to_normalize:\n    max_value = field[column].max()\n    norm_field[column] = field[column] / max_value\n\n# Show the first few rows of the normalized DataFrame\nnorm_field.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.386177Z","iopub.execute_input":"2024-08-02T12:18:37.386544Z","iopub.status.idle":"2024-08-02T12:18:37.412985Z","shell.execute_reply.started":"2024-08-02T12:18:37.386509Z","shell.execute_reply":"2024-08-02T12:18:37.411661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of columns to normalize (excluding the 'Player' column)\ncolumns_to_normalize = wik.columns.to_list()[1:]\n\n# Create a new DataFrame 'norm_wik' with the same columns as 'wik'\nnorm_wik = pd.DataFrame(columns=wik.columns)\n\n# Copy the 'Player' column to the new DataFrame\nnorm_wik['Player'] = wik['Player']\n\n# Normalize columns by dividing each value by the column's maximum value\nfor column in columns_to_normalize:\n    max_value = wik[column].max()\n    norm_wik[column] = wik[column] / max_value\n\n# Show the first few rows of the normalized DataFrame\nnorm_wik.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.414623Z","iopub.execute_input":"2024-08-02T12:18:37.415073Z","iopub.status.idle":"2024-08-02T12:18:37.440231Z","shell.execute_reply.started":"2024-08-02T12:18:37.415034Z","shell.execute_reply":"2024-08-02T12:18:37.43766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PCA on Normalized Data**","metadata":{}},{"cell_type":"code","source":"# Initialize the StandardScaler to standardize features by removing the mean and scaling to unit variance\nscaler = StandardScaler()\n\n# Prepare the feature data for scaling by dropping the 'Player' column\nbat_features = norm_bat.drop('Player', axis=1, inplace=False)\n\n# Apply scaling to the feature data\nscaled_bat_data = scaler.fit_transform(bat_features)\n\n# Initialize PCA for dimensionality reduction\npca = PCA()\n\n# Apply PCA to the scaled data\npca_result = pca.fit_transform(scaled_bat_data)\n\n# Retrieve the explained variance ratio for each principal component\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Retrieve the component loadings (principal axes in feature space)\ncomponent_loadings = pca.components_\n\n# Initialize an array to store the weights for each feature\nbat_weights = np.zeros(bat_features.shape[1])\n\n# Compute the weight of each feature based on its loadings and explained variance\nfor i in range(len(explained_variance_ratio)):\n    bat_weights += np.abs(component_loadings[i]) * explained_variance_ratio[i]\n\n# Normalize the weights so that they sum to 1\ntotal_weight = np.sum(bat_weights)\nfor i in range(len(bat_weights)):\n    bat_weights[i] /= total_weight\n\n# Create a DataFrame to display feature weights\nbat_weights = pd.DataFrame({\n    'features': bat_features.columns,\n    'weight': bat_weights.tolist()\n})\n\n# Display the DataFrame with feature weights\nbat_weights","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.442416Z","iopub.execute_input":"2024-08-02T12:18:37.443165Z","iopub.status.idle":"2024-08-02T12:18:37.491918Z","shell.execute_reply.started":"2024-08-02T12:18:37.443123Z","shell.execute_reply":"2024-08-02T12:18:37.489926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a figure for the Scree Plot with a specified size\nplt.figure(figsize=(10, 6))\n\n# Plot the explained variance ratio for each principal component\n# The x-axis represents the principal component index, and the y-axis represents the variance explained\nplt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\n\n# Set the title of the plot\nplt.title('Scree Plot')\n\n# Label the x-axis\nplt.xlabel('Principal Component')\n\n# Label the y-axis\nplt.ylabel('Variance Explained')\n\n# Add a grid to the plot for better readability\nplt.grid(True)\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.494729Z","iopub.execute_input":"2024-08-02T12:18:37.495502Z","iopub.status.idle":"2024-08-02T12:18:37.84409Z","shell.execute_reply.started":"2024-08-02T12:18:37.495459Z","shell.execute_reply":"2024-08-02T12:18:37.842908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loadings Plot\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\nnum_vars = len(bat_features.columns)\nplt.figure(figsize=(10, 6))\nfor i in range(num_vars):\n    plt.plot([0, loadings[i, 0]], [0, loadings[i, 1]], 'b-')\n    plt.text(loadings[i, 0], loadings[i, 1], bat_features.columns[i], fontsize=12)\n\nplt.title('Loadings Plot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:37.845551Z","iopub.execute_input":"2024-08-02T12:18:37.845987Z","iopub.status.idle":"2024-08-02T12:18:38.168194Z","shell.execute_reply.started":"2024-08-02T12:18:37.84595Z","shell.execute_reply":"2024-08-02T12:18:38.167034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Biplot\nplt.figure(figsize=(10, 6))\nplt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', marker='o')\nplt.title('Biplot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\nfor i in range(num_vars):\n    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.5)\n    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, bat_features.columns[i], color='g', ha='center', va='center')\n\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:38.169779Z","iopub.execute_input":"2024-08-02T12:18:38.170299Z","iopub.status.idle":"2024-08-02T12:18:38.495202Z","shell.execute_reply.started":"2024-08-02T12:18:38.170259Z","shell.execute_reply":"2024-08-02T12:18:38.494045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the StandardScaler to standardize features\nscaler = StandardScaler()\n\n# Prepare the feature data for scaling by dropping the 'Player' column\nbowl_features = norm_bowl.drop('Player', axis=1, inplace=False)\n\n# Apply scaling to the feature data\nscaled_bowl_data = scaler.fit_transform(bowl_features)\n\n# Initialize PCA for dimensionality reduction\npca = PCA()\n\n# Apply PCA to the scaled data\npca_result = pca.fit_transform(scaled_bowl_data)\n\n# Retrieve the explained variance ratio for each principal component\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Retrieve the component loadings (principal axes in feature space)\ncomponent_loadings = pca.components_\n\n# Initialize an array to store the weights for each feature\nbowl_weights = np.zeros(bowl_features.shape[1])\n\n# Compute the weight of each feature based on its loadings and explained variance\nfor i in range(len(explained_variance_ratio)):\n    bowl_weights += np.abs(component_loadings[i]) * explained_variance_ratio[i]\n\n# Normalize the weights so that they sum to 1\ntotal_weight = np.sum(bowl_weights)\nfor i in range(len(bowl_weights)):\n    bowl_weights[i] /= total_weight\n\n# Create a DataFrame to display feature weights\nbowl_weights = pd.DataFrame({\n    'features': bowl_features.columns,\n    'weight': bowl_weights.tolist()\n})\n\n# Display the DataFrame with feature weights\nbowl_weights","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:38.496722Z","iopub.execute_input":"2024-08-02T12:18:38.4971Z","iopub.status.idle":"2024-08-02T12:18:38.520227Z","shell.execute_reply.started":"2024-08-02T12:18:38.49707Z","shell.execute_reply":"2024-08-02T12:18:38.518922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scree Plot\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:38.521912Z","iopub.execute_input":"2024-08-02T12:18:38.522275Z","iopub.status.idle":"2024-08-02T12:18:38.806007Z","shell.execute_reply.started":"2024-08-02T12:18:38.522246Z","shell.execute_reply":"2024-08-02T12:18:38.804885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loadings Plot\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\nnum_vars = len(bowl_features.columns)\nplt.figure(figsize=(10, 6))\nfor i in range(num_vars):\n    plt.plot([0, loadings[i, 0]], [0, loadings[i, 1]], 'b-')\n    plt.text(loadings[i, 0], loadings[i, 1], bowl_features.columns[i], fontsize=12)\n\nplt.title('Loadings Plot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:38.807371Z","iopub.execute_input":"2024-08-02T12:18:38.807721Z","iopub.status.idle":"2024-08-02T12:18:39.098345Z","shell.execute_reply.started":"2024-08-02T12:18:38.807693Z","shell.execute_reply":"2024-08-02T12:18:39.097297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Biplot\nplt.figure(figsize=(10, 6))\nplt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', marker='o')\nplt.title('Biplot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\nfor i in range(num_vars):\n    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.5)\n    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, bowl_features.columns[i], color='g', ha='center', va='center')\n\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:39.101674Z","iopub.execute_input":"2024-08-02T12:18:39.102023Z","iopub.status.idle":"2024-08-02T12:18:39.394562Z","shell.execute_reply.started":"2024-08-02T12:18:39.101997Z","shell.execute_reply":"2024-08-02T12:18:39.393026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the StandardScaler to standardize features\nscaler = StandardScaler()\n\n# Prepare the feature data for scaling by dropping the 'Player' column\nfield_features = norm_field.drop('Player', axis=1, inplace=False)\n\n# Apply scaling to the feature data\nscaled_field_data = scaler.fit_transform(field_features)\n\n# Initialize PCA for dimensionality reduction\npca = PCA()\n\n# Apply PCA to the scaled data\npca_result = pca.fit_transform(scaled_field_data)\n\n# Retrieve the explained variance ratio for each principal component\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Retrieve the component loadings (principal axes in feature space)\ncomponent_loadings = pca.components_\n\n# Initialize an array to store the weights for each feature\nfield_weights = np.zeros(field_features.shape[1])\n\n# Compute the weight of each feature based on its loadings and explained variance\nfor i in range(len(explained_variance_ratio)):\n    field_weights += np.abs(component_loadings[i]) * explained_variance_ratio[i]\n\n# Normalize the weights so that they sum to 1\ntotal_weight = np.sum(field_weights)\nfor i in range(len(field_weights)):\n    field_weights[i] /= total_weight\n\n# Create a DataFrame to display feature weights\nfield_weights = pd.DataFrame({\n    'features': field_features.columns,\n    'weight': field_weights.tolist()\n})\n\n# Display the DataFrame with feature weights\nfield_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:39.396206Z","iopub.execute_input":"2024-08-02T12:18:39.396566Z","iopub.status.idle":"2024-08-02T12:18:39.421541Z","shell.execute_reply.started":"2024-08-02T12:18:39.396536Z","shell.execute_reply":"2024-08-02T12:18:39.420372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scree Plot\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:39.422938Z","iopub.execute_input":"2024-08-02T12:18:39.423345Z","iopub.status.idle":"2024-08-02T12:18:39.728881Z","shell.execute_reply.started":"2024-08-02T12:18:39.423311Z","shell.execute_reply":"2024-08-02T12:18:39.727703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loadings Plot\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\nnum_vars = len(field_features.columns)\nplt.figure(figsize=(10, 6))\nfor i in range(num_vars):\n    plt.plot([0, loadings[i, 0]], [0, loadings[i, 1]], 'b-')\n    plt.text(loadings[i, 0], loadings[i, 1], field_features.columns[i], fontsize=12)\n\nplt.title('Loadings Plot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:39.730601Z","iopub.execute_input":"2024-08-02T12:18:39.731019Z","iopub.status.idle":"2024-08-02T12:18:40.035202Z","shell.execute_reply.started":"2024-08-02T12:18:39.730982Z","shell.execute_reply":"2024-08-02T12:18:40.034129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Biplot\nplt.figure(figsize=(10, 6))\nplt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', marker='o')\nplt.title('Biplot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\nfor i in range(num_vars):\n    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.5)\n    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, field_features.columns[i], color='g', ha='center', va='center')\n\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:40.036546Z","iopub.execute_input":"2024-08-02T12:18:40.036913Z","iopub.status.idle":"2024-08-02T12:18:40.356322Z","shell.execute_reply.started":"2024-08-02T12:18:40.036885Z","shell.execute_reply":"2024-08-02T12:18:40.355037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the StandardScaler to standardize features\nscaler = StandardScaler()\n\n# Prepare the feature data for scaling by dropping the 'Player' column\nwik_features = norm_wik.drop('Player', axis=1, inplace=False)\n\n# Apply scaling to the feature data\nscaled_wik_data = scaler.fit_transform(wik_features)\n\n# Initialize PCA for dimensionality reduction\npca = PCA()\n\n# Apply PCA to the scaled data\npca_result = pca.fit_transform(scaled_wik_data)\n\n# Retrieve the explained variance ratio for each principal component\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Retrieve the component loadings (principal axes in feature space)\ncomponent_loadings = pca.components_\n\n# Initialize an array to store the weights for each feature\nwik_weights = np.zeros(wik_features.shape[1])\n\n# Compute the weight of each feature based on its loadings and explained variance\nfor i in range(len(explained_variance_ratio)):\n    wik_weights += np.abs(component_loadings[i]) * explained_variance_ratio[i]\n\n# Normalize the weights so that they sum to 1\ntotal_weight = np.sum(wik_weights)\nfor i in range(len(wik_weights)):\n    wik_weights[i] /= total_weight\n\n# Create a DataFrame to display feature weights\nwik_weights = pd.DataFrame({\n    'features': wik_features.columns,\n    'weight': wik_weights.tolist()\n})\n\n# Display the DataFrame with feature weights for wicketkeepers\nwik_weights\n\n# Display the DataFrame with feature weights for batsmen\nbat_weights","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:40.357872Z","iopub.execute_input":"2024-08-02T12:18:40.358312Z","iopub.status.idle":"2024-08-02T12:18:40.382639Z","shell.execute_reply.started":"2024-08-02T12:18:40.358274Z","shell.execute_reply":"2024-08-02T12:18:40.381367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scree Plot\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:40.384221Z","iopub.execute_input":"2024-08-02T12:18:40.384709Z","iopub.status.idle":"2024-08-02T12:18:40.681676Z","shell.execute_reply.started":"2024-08-02T12:18:40.384666Z","shell.execute_reply":"2024-08-02T12:18:40.68038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loadings Plot\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\nnum_vars = len(wik_features.columns)\nplt.figure(figsize=(10, 6))\nfor i in range(num_vars):\n    plt.plot([0, loadings[i, 0]], [0, loadings[i, 1]], 'b-')\n    plt.text(loadings[i, 0], loadings[i, 1], wik_features.columns[i], fontsize=12)\n\nplt.title('Loadings Plot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:40.683274Z","iopub.execute_input":"2024-08-02T12:18:40.683715Z","iopub.status.idle":"2024-08-02T12:18:40.993053Z","shell.execute_reply.started":"2024-08-02T12:18:40.683676Z","shell.execute_reply":"2024-08-02T12:18:40.991758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Biplot\nplt.figure(figsize=(10, 6))\nplt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', marker='o')\nplt.title('Biplot')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\nfor i in range(num_vars):\n    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.5)\n    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, wik_features.columns[i], color='g', ha='center', va='center')\n\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:40.994282Z","iopub.execute_input":"2024-08-02T12:18:40.994595Z","iopub.status.idle":"2024-08-02T12:18:41.277993Z","shell.execute_reply.started":"2024-08-02T12:18:40.99457Z","shell.execute_reply":"2024-08-02T12:18:41.276859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Calculate scores using the weights determined by PCA**","metadata":{}},{"cell_type":"code","source":"# Calculate the 'bat_score' for each player by applying feature weights to normalized batting data\n# Multiply each feature by its corresponding weight and sum the results to get the bat_score\nnorm_bat['bat_score'] = (bat_features * np.array(bat_weights.T.loc['weight',])).sum(axis=1)\n\n# Calculate the 'bowl_score' for each player by applying feature weights to normalized bowling data\n# Multiply each feature by its corresponding weight and sum the results to get the bowl_score\nnorm_bowl['bowl_score'] = (bowl_features * np.array(bowl_weights.T.loc['weight',])).sum(axis=1)\n\n# Calculate the 'field_score' for each player by applying feature weights to normalized fielding data\n# Multiply each feature by its corresponding weight and sum the results to get the field_score\nnorm_field['field_score'] = (field_features * np.array(field_weights.T.loc['weight',])).sum(axis=1)\n\n# Calculate the 'wik_score' for each player by applying feature weights to normalized wicketkeeper data\n# Multiply each feature by its corresponding weight and sum the results to get the wik_score\nnorm_wik['wik_score'] = (wik_features * np.array(wik_weights.T.loc['weight',])).sum(axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:41.279368Z","iopub.execute_input":"2024-08-02T12:18:41.279706Z","iopub.status.idle":"2024-08-02T12:18:41.299672Z","shell.execute_reply.started":"2024-08-02T12:18:41.279679Z","shell.execute_reply":"2024-08-02T12:18:41.298493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Rename columns to reduce errors**","metadata":{}},{"cell_type":"code","source":"# Rename columns of the normalized batting DataFrame to descriptive names\n# The new names correspond to the metrics and the calculated 'bat_score'\nnorm_bat.columns = ['Player', 'bat_Mat', 'bat_Inns', 'bat_Runs', 'HS', 'bat_Ave', 'SR', 'HalfCenturies', 'Ducks', 'bat_score']\n\n# Rename columns of the normalized bowling DataFrame to descriptive names\n# The new names correspond to the metrics and the calculated 'bowl_score'\nnorm_bowl.columns = ['Player', 'bowl_Mat', 'bowl_Inns', 'Mdns', 'bowl_Runs', 'Wkts', 'bowl_Ave', 'Econ', 'bowl_score']\n\n# Rename columns of the normalized fielding DataFrame to descriptive names\n# The new names correspond to the metrics and the calculated 'field_score'\nnorm_field.columns = ['Player', 'field_Mat', 'field_Inns', 'field_Ct', 'Max', 'Ct/Inn', 'field_score']\n\n# Rename columns of the normalized wicketkeeper DataFrame to descriptive names\n# The new names correspond to the metrics and the calculated 'wik_score'\nnorm_wik.columns = ['Player', 'wik_Mat', 'wik_Inns', 'Dis', 'wik_Ct', 'St', 'Max Dis Inns', 'Dis/Inn', 'wik_score']\n","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:41.301406Z","iopub.execute_input":"2024-08-02T12:18:41.301949Z","iopub.status.idle":"2024-08-02T12:18:41.317468Z","shell.execute_reply.started":"2024-08-02T12:18:41.301877Z","shell.execute_reply":"2024-08-02T12:18:41.315964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merge Data and fill NaN values**","metadata":{}},{"cell_type":"code","source":"# Merge the normalized batting, bowling, fielding, and wicketkeeper DataFrames on the 'Player' column\n# Use an outer join to include all players, even if they are missing data in some categories\nmerged_data = pd.merge(norm_bat, norm_bowl, on='Player', how='outer')\nmerged_data = pd.merge(merged_data, norm_field, on='Player', how='outer')\nmerged_data = pd.merge(merged_data, norm_wik, on='Player', how='outer')\n\n# Convert the score columns to numeric type to ensure correct calculations and handling\nmerged_data['bat_score'] = pd.to_numeric(merged_data['bat_score'])\nmerged_data['bowl_score'] = pd.to_numeric(merged_data['bowl_score'])\nmerged_data['field_score'] = pd.to_numeric(merged_data['field_score'])\nmerged_data['wik_score'] = pd.to_numeric(merged_data['wik_score'])\n\n# Replace any missing values in the DataFrame with 0\n# This ensures that calculations and analysis do not encounter errors due to NaNs\nmerged_data.fillna(0, inplace=True)\n\n# Display descriptive statistics of the merged DataFrame\n# This provides an overview of the data, including means, standard deviations, and ranges for each column\nmerged_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:41.318928Z","iopub.execute_input":"2024-08-02T12:18:41.319337Z","iopub.status.idle":"2024-08-02T12:18:41.42787Z","shell.execute_reply.started":"2024-08-02T12:18:41.319306Z","shell.execute_reply":"2024-08-02T12:18:41.426813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classify Data**","metadata":{}},{"cell_type":"code","source":"# Calculate the 75th percentile thresholds for the scores to classify players\nwik_score_high = merged_data['wik_score'].quantile(0.75)\nbat_score_high = merged_data['bat_score'].quantile(0.75)\nbowl_score_high = merged_data['bowl_score'].quantile(0.75)\n\n# Define a function to classify players based on their scores\n# The function checks if a player qualifies for a specific role based on score thresholds\ndef classify_player(row):\n    # Check if the player qualifies as a Wicketkeeper\n    if row['wik_score'] > wik_score_high:\n        return 'Wicketkeeper'\n    # Check if the player qualifies as an All-rounder\n    elif row['bat_score'] > bat_score_high and row['bowl_score'] > bowl_score_high:\n        return 'All_rounder'\n    # Check if the player qualifies as a Bowler\n    elif row['bowl_score'] > bowl_score_high:\n        return 'Bowler'\n    # Check if the player qualifies as a Batsman\n    elif row['bat_score'] > bat_score_high:\n        return 'Batsman'\n    else:\n        return 'Bad_Player'\n\n# Apply the classification function to each row of the merged DataFrame\n# Add a new column 'Role' to store the classification result\nmerged_data['Role'] = merged_data.apply(classify_player, axis=1)\n\n# Display the first few rows of the DataFrame with the new 'Role' column\nmerged_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:41.429105Z","iopub.execute_input":"2024-08-02T12:18:41.4294Z","iopub.status.idle":"2024-08-02T12:18:41.471675Z","shell.execute_reply.started":"2024-08-02T12:18:41.429377Z","shell.execute_reply":"2024-08-02T12:18:41.470547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generate the final team**","metadata":{}},{"cell_type":"code","source":"# Create an empty DataFrame with the same columns as 'merged_data' to store the final team\nfinal_11 = pd.DataFrame(columns=merged_data.columns)\n\n# Select the top player with the highest 'wik_score', 'bat_score', and 'field_score' as the Wicketkeeper\nwk = merged_data.sort_values(by=['wik_score', 'bat_score', 'field_score'], ascending=False).head(1)\n\n# Select the top 4 Batsmen based on 'bat_score' and 'field_score'\nbm = merged_data[merged_data['Role'] == 'Batsman'].sort_values(by=['bat_score', 'field_score'], ascending=False).head(4)\n\n# Select the top 3 All-rounders based on 'bat_score', 'bowl_score', and 'field_score'\nar = merged_data[merged_data['Role'] == 'All_rounder'].sort_values(by=['bat_score', 'bowl_score', 'field_score'], ascending=False).head(3)\n\n# Select the top 3 Bowlers based on 'bowl_score' and 'field_score'\nbw = merged_data[merged_data['Role'] == 'Bowler'].sort_values(by=['bowl_score', 'field_score'], ascending=False).head(3)\n\n# Concatenate the selected players into the 'final_11' DataFrame\nfinal_11 = pd.concat([final_11, wk, bm, ar, bw])\n\n# Reset the index of 'final_11' to ensure a continuous index\nfinal_11.reset_index(drop=True, inplace=True)\n\n# Display the final team selection\nfinal_11","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:41.473015Z","iopub.execute_input":"2024-08-02T12:18:41.473343Z","iopub.status.idle":"2024-08-02T12:18:41.526235Z","shell.execute_reply.started":"2024-08-02T12:18:41.473316Z","shell.execute_reply":"2024-08-02T12:18:41.525048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}